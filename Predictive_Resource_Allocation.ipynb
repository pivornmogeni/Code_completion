{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Predictive Analytics for Resource Allocation\n", "**Dataset:** Kaggle Breast Cancer Dataset\n", "\n", "**Goal:** Predict issue priority (high/medium/low) using Random Forest\n", "\n", "**Steps:**\n", "- Load and preprocess the data\n", "- Create simulated issue priority labels\n", "- Train a Random Forest model\n", "- Evaluate with Accuracy and F1-score\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import libraries\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load dataset\n", "df = pd.read_csv('data.csv')  # Place 'data.csv' in the same directory\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Preprocess dataset\n", "df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)\n", "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n", "\n", "# Simulate issue priority\n", "def assign_priority(row):\n", "    if row['diagnosis'] == 1 and row['area_mean'] > 1000:\n", "        return 'high'\n", "    elif row['diagnosis'] == 0 and row['texture_mean'] < 15:\n", "        return 'low'\n", "    else:\n", "        return 'medium'\n", "\n", "df['issue_priority'] = df.apply(assign_priority, axis=1)\n", "priority_map = {'low': 0, 'medium': 1, 'high': 2}\n", "df['priority_label'] = df['issue_priority'].map(priority_map)\n", "df.drop(['diagnosis', 'issue_priority'], axis=1, inplace=True)\n", "\n", "# Feature/target split\n", "X = df.drop('priority_label', axis=1)\n", "y = df['priority_label']\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train model\n", "model = RandomForestClassifier(n_estimators=100, random_state=42)\n", "model.fit(X_train, y_train)\n", "y_pred = model.predict(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Evaluate model\n", "acc = accuracy_score(y_test, y_pred)\n", "f1 = f1_score(y_test, y_pred, average='weighted')\n", "\n", "print(f\"Accuracy: {acc:.2f}\")\n", "print(f\"F1 Score: {f1:.2f}\")\n", "print(\"\\nClassification Report:\")\n", "print(classification_report(y_test, y_pred))\n", "\n", "# Confusion Matrix\n", "cm = confusion_matrix(y_test, y_pred)\n", "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=priority_map.keys(), yticklabels=priority_map.keys())\n", "plt.xlabel(\"Predicted\")\n", "plt.ylabel(\"Actual\")\n", "plt.title(\"Confusion Matrix\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Feature importance\n", "importances = pd.Series(model.feature_importances_, index=X.columns)\n", "importances.nlargest(10).plot(kind='barh')\n", "plt.title(\"Top 10 Feature Importances\")\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 2}